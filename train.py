# -*- coding: utf-8 -*-
"""train.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16a0xfLMDr5g8t6L2dhDwycoYQ5GK_j9h
"""

# =====================================
# 1. Import Libraries
# =====================================
import pandas as pd
import numpy as np

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, f1_score, recall_score, confusion_matrix
)

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

import joblib


# =====================================
# 2. Load Dataset
# =====================================
df = pd.read_csv("bank.csv")   # change path if needed

# Target encoding
df['y'] = df['y'].map({'yes': 1, 'no': 0})


# =====================================
# 3. Feature Classification
# =====================================
one_hot_cols = [
    'job', 'marital', 'default', 'housing',
    'loan', 'contact', 'poutcome', 'month'
]

ordinal_col = ['education']

numeric_cols = [
    col for col in df.columns
    if col not in one_hot_cols + ordinal_col + ['y']
]


# =====================================
# 4. Preprocessing Pipeline
# =====================================
preprocess = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'), one_hot_cols),
        ('ordinal', OrdinalEncoder(), ordinal_col),
        ('scale', MinMaxScaler(), numeric_cols)
    ]
)


# =====================================
# 5. Split Features & Target
# =====================================
X = df.drop('y', axis=1)
y = df['y']


# =====================================
# 6. Train-Test Split (RAW DATA)
# =====================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)


# =====================================
# 7. Define Models
# =====================================
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest Gini": RandomForestClassifier(
        criterion='gini', n_estimators=100, random_state=42
    ),
    "Random Forest Entropy": RandomForestClassifier(
        criterion='entropy', n_estimators=100, random_state=42
    ),
    "SVM Linear": SVC(kernel='linear', C=0.1, probability=True),
    "SVM Poly": SVC(kernel='poly', degree=3, C=0.1, probability=True)
}


# =====================================
# 8. Train Models using FULL PIPELINE
#    (Preprocess + SMOTE + Model)
# =====================================
results = {}
trained_pipelines = {}

for name, model in models.items():

    pipeline = ImbPipeline(steps=[
        ('preprocess', preprocess),
        ('smote', SMOTE(sampling_strategy='minority', random_state=42)),
        ('model', model)
    ])

    pipeline.fit(X_train, y_train)

    y_pred = pipeline.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    results[name] = acc
    trained_pipelines[name] = pipeline


# =====================================
# 9. Select Best Model
# =====================================
best_model_name = max(results, key=results.get)
best_pipeline = trained_pipelines[best_model_name]

print("Model Scores:")
for k, v in results.items():
    print(f"{k}: {v:.4f}")

print(f"\nBest Model: {best_model_name}")
print(f"Best Accuracy: {results[best_model_name]:.4f}")


# =====================================
# 10. Final Evaluation
# =====================================
y_best_pred = best_pipeline.predict(X_test)

print("\nEvaluation Metrics:")
print("Accuracy:", accuracy_score(y_test, y_best_pred))
print("Recall:", recall_score(y_test, y_best_pred))
print("F1 Score:", f1_score(y_test, y_best_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_best_pred))


# =====================================
# 11. Save FINAL DEPLOYMENT MODEL
# =====================================
joblib.dump(best_pipeline, "bank_marketing_model.pkl")

print("\nâœ… Model saved as bank_marketing_model.pkl")
